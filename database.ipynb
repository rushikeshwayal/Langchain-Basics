{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Using cached sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from sentence_transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from sentence_transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from sentence_transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from sentence_transformers) (0.29.1)\n",
      "Requirement already satisfied: Pillow in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from sentence_transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\machine learning\\langchain\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.1.31)\n",
      "Using cached sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Installing collected packages: sentence_transformers\n",
      "Successfully installed sentence_transformers-3.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Machine Learning\\Langchain\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Machine Learning\\Langchain\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rushi\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating a piece of bread.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "    \"A woman is playing violin.\",\n",
    "    \"Two men pushed carts through the woods.\",\n",
    "    \"A man is riding a white horse on an enclosed ground.\",\n",
    "    \"A monkey is playing drums.\",\n",
    "    \"A cheetah is running behind its prey.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 384)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(\n",
    "  database=\"vect\",\n",
    "  user=\"postgres\",\n",
    "  password=\"newpassword\",\n",
    "  port=5432\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "InFailedSqlTransaction",
     "evalue": "current transaction is aborted, commands ignored until end of transaction block\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInFailedSqlTransaction\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(corpus, embeddings):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mINSERT INTO items (text, embedding) VALUES (\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m      5\u001b[0m cursor\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mInFailedSqlTransaction\u001b[0m: current transaction is aborted, commands ignored until end of transaction block\n"
     ]
    }
   ],
   "source": [
    "for text, emb in zip(corpus, embeddings):\n",
    "    cursor.execute(\"INSERT INTO items (text, embedding) VALUES (%s, %s)\", (text, np.array(emb).tolist()))\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_emb = embeddings[0].tolist()\n",
    "cursor.execute(f\"SELECT * FROM items ORDER BY embedding <-> '{query_emb}' LIMIT 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating a piece of bread.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "    \"A woman is playing violin.\",\n",
    "    \"Two men pushed carts through the woods.\",\n",
    "    \"A man is riding a white horse on an enclosed ground.\",\n",
    "    \"A monkey is playing drums.\",\n",
    "    \"A cheetah is running behind its prey.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    database=\"vect\",\n",
    "    user=\"postgres\",\n",
    "    password=\"newpassword\",\n",
    "    host=\"127.0.0.1\",\n",
    "    port=5432\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Ensure the table exists\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS items (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        text TEXT,\n",
    "        embedding vector(384) -- Change 1536 to match your embedding size\n",
    "    )\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# Sample data\n",
    "# corpus = [\"Hello world\", \"Postgres with pgvector\"]\n",
    "embeddings = [np.random.rand(384), np.random.rand(384 )]  # Example embeddings\n",
    "\n",
    "# Insert data\n",
    "for text, emb in zip(corpus, embeddings):\n",
    "    cursor.execute(\"INSERT INTO items (text, embedding) VALUES (%s, %s)\", (text, np.array(emb).tolist()))\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
